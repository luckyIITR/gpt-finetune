{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e9d928-641a-4c73-98bf-ffba2d297041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d076be-4e9b-4e1d-81a3-00f006b4162d",
   "metadata": {},
   "source": [
    "### Let's try original model using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4f6ee2-662f-4a10-9cb1-7bdb567f037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f11ea7-2103-4a47-a6e8-c98bb99e87c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"fill-mask\", model=\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8bf7d7-f06a-44bb-a8a7-0b6152aa6008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11076898872852325,\n",
       "  'token': 5914,\n",
       "  'token_str': 'marry',\n",
       "  'sequence': 'today i will marry you.'},\n",
       " {'score': 0.039211247116327286,\n",
       "  'token': 3113,\n",
       "  'token_str': 'meet',\n",
       "  'sequence': 'today i will meet you.'},\n",
       " {'score': 0.031348153948783875,\n",
       "  'token': 2393,\n",
       "  'token_str': 'help',\n",
       "  'sequence': 'today i will help you.'},\n",
       " {'score': 0.030156586319208145,\n",
       "  'token': 2156,\n",
       "  'token_str': 'see',\n",
       "  'sequence': 'today i will see you.'},\n",
       " {'score': 0.02977384440600872,\n",
       "  'token': 2425,\n",
       "  'token_str': 'tell',\n",
       "  'sequence': 'today i will tell you.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today I will [MASK] you.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9ab8a-e768-4c35-aa31-fa438b2fd7ba",
   "metadata": {},
   "source": [
    "### Load IMDb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d7a85b-3d1d-4b29-8efc-3e489d68ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a227c2-42ba-45ca-9044-eaabfe93b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/lucky/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4721b73415e04f2095f623db280e4481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = load_dataset(\"imdb\").shuffle()\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7578c12a-c33c-4a73-bf03-eb0361cfc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['train'] = imdb['train'].select(range(10))\n",
    "imdb['test'] = imdb['test'].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d216c11-6599-41ff-aa8f-a51bcfe020a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    7\n",
       "0    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['test'].to_pandas()['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb518bb-bd64-4847-b8bf-2902f0188c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"Bride of Chucky\" is one of the better horror movies to come out in the past ten years and could be one of the best horror films of the 90\\'s.<br /><br />**SPOILERS**<br /><br />Chucky\\'s girlfriend, Tiffany (Jennifer Tilly) manages to find his battered remains after being sucked into the fan at the end of part 3 and brings him to life in her trailer park. Her neighbor, Jessie (Nick Stabile) and his girlfriend Jade (Katherine Heigl) are being tormented by her uncle. (John Ritter) Tiffany upsets Chucky when he refuses to marry her, so she buys a doll for him to play with. Chucky kills Tiffany, and then transfers her soul into the doll she got him. In order for them to be placed back into human bodies, they have to travel to New Jersey to retrieve an amulet to do so. Jessie sees this as an opportunity to escape from Ritter, and they set out on the journey, but not before Ritter is killed by Chucky and Tiffany. Along the way, several bizarre incidents force them to stop at a bed and breakfast. When several more people are killed, they call up their best friend (Gordon Woolvett) to straighten out the situation. They convince him neither one of them are the killers, as the police have began to solve the crimes. He finds Ritter\\'s body in a trunk in the back of the van. Thinking he has been set up, he confronts them about it. Chucky and Tiffany then turn real to prove they did it, which gets Woolvett killed. The group steals a motor home and arrives at the cemetery. Jessie and Jade get Chucky and Tiffany to turn on each other, giving them enough to escape. Chucky recaptures Jade and forces her to get his amulet. Chucky and Tiffany restart their feud, which gives Jessie and Jade enough time to kill the both of them as the police arrive and clears them of the crimes.<br /><br />The Good News: I have to give the most amount of props to the FX department, as Chucky and Tiffany as dolls look completely convincing. The scenes with them together are the movies main highlights, including a hilarious conversation where Tiffany advises Chucky on how serial killers in the 90\\'s work. That being said, the amount of one-liners in this movie that are actually funny is incredible. Chucky gets the most of them, but Tiffany cracks a few gems as well. It is actually funnier than what Hollywood calls comedies these days. The gore is plentiful and shockingly realistic. Several deaths in this movie are actually original and creative. Turning Ritter into a new form of Pinhead was a totally brilliant scene. The honeymooning couple was a nice death scene, as well. For teenage love, the pairing of Stabile and Heigl works great. They have a great chemistry together and actually behave like a normal couple. I also have to admit that the first time I saw this movie, I did jump during certain scenes, and that shows what an incredible job director Yu did. He learned enough, apparently, to do the same thing with \"Freddy vs. Jason.\" He knows how to stage set-ups and pay-offs, and here he shows some great skills that have a Hong Kong influenced look and style. He could be the next great horror director if he keeps filling up his resume with films like those two. Nice soundtrack, too, like \"Freddy vs. Jason.\"<br /><br />The Bad News: For fans of cheesy movies, this will be a great find. However, this film has a high cheese factor that may prevent the serious horror movie fan from having a good time enjoying this film. The film knows it is a cheesy movie and revels in it, making a serious fan turned off because of things like the one-liners. It isn\\'t all that bad of a movie, but it has to be watched in the mind frame that it is a cheesy movie, and that the cheesiness of certain scenes add to the movie, not to take it away. Remove yourself from that state of mind and you may find yourself enjoying this movie.<br /><br />The Final Verdict: Fans of cheesy movies and the other \"Child\\'s Play\" movies will find a lot to like about this movie. For serious horror fans, take a look at it, but keep in mind that it isn\\'t a serious movie and that the cheesiness is supposed to be there and you might find yourself liking it.<br /><br />Rated R: Graphic Violence, Graphic Language, Brief Nudity on a doll, a shadowy puppet sex scene, some drug use, and numerous drug references.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['test'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b265b-5fa9-43b2-a65d-855e1e4f7227",
   "metadata": {},
   "source": [
    "### let's preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ac8778-854b-4f30-8c31-5d2b9a15f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bab501-bdd8-4fc2-97a1-bf5cf14287a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec5e371a-d0f2-4082-8a11-bdfa4b8d4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fxn(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9509042-054f-42d5-ae7b-547b4a4d8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_fxn at 0x3526045e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31382f941d7f4f3d9022dcc159aa5562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21cc79826514249be7f37ba0aa801f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e643a947fa4666aa24afc4b56f50b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_fxn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d1f39a-18d9-4e98-acaf-3a952670f501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '\"Bride of Chucky\" is one of the better horror movies to come out in the past ten years and could be one of the best horror films of the 90\\'s.<br /><br />**SPOILERS**<br /><br />Chucky\\'s girlfriend, Tiffany (Jennifer Tilly) manages to find his battered remains after being sucked into the fan at the end of part 3 and brings him to life in her trailer park. Her neighbor, Jessie (Nick Stabile) and his girlfriend Jade (Katherine Heigl) are being tormented by her uncle. (John Ritter) Tiffany upsets Chucky when he refuses to marry her, so she buys a doll for him to play with. Chucky kills Tiffany, and then transfers her soul into the doll she got him. In order for them to be placed back into human bodies, they have to travel to New Jersey to retrieve an amulet to do so. Jessie sees this as an opportunity to escape from Ritter, and they set out on the journey, but not before Ritter is killed by Chucky and Tiffany. Along the way, several bizarre incidents force them to stop at a bed and breakfast. When several more people are killed, they call up their best friend (Gordon Woolvett) to straighten out the situation. They convince him neither one of them are the killers, as the police have began to solve the crimes. He finds Ritter\\'s body in a trunk in the back of the van. Thinking he has been set up, he confronts them about it. Chucky and Tiffany then turn real to prove they did it, which gets Woolvett killed. The group steals a motor home and arrives at the cemetery. Jessie and Jade get Chucky and Tiffany to turn on each other, giving them enough to escape. Chucky recaptures Jade and forces her to get his amulet. Chucky and Tiffany restart their feud, which gives Jessie and Jade enough time to kill the both of them as the police arrive and clears them of the crimes.<br /><br />The Good News: I have to give the most amount of props to the FX department, as Chucky and Tiffany as dolls look completely convincing. The scenes with them together are the movies main highlights, including a hilarious conversation where Tiffany advises Chucky on how serial killers in the 90\\'s work. That being said, the amount of one-liners in this movie that are actually funny is incredible. Chucky gets the most of them, but Tiffany cracks a few gems as well. It is actually funnier than what Hollywood calls comedies these days. The gore is plentiful and shockingly realistic. Several deaths in this movie are actually original and creative. Turning Ritter into a new form of Pinhead was a totally brilliant scene. The honeymooning couple was a nice death scene, as well. For teenage love, the pairing of Stabile and Heigl works great. They have a great chemistry together and actually behave like a normal couple. I also have to admit that the first time I saw this movie, I did jump during certain scenes, and that shows what an incredible job director Yu did. He learned enough, apparently, to do the same thing with \"Freddy vs. Jason.\" He knows how to stage set-ups and pay-offs, and here he shows some great skills that have a Hong Kong influenced look and style. He could be the next great horror director if he keeps filling up his resume with films like those two. Nice soundtrack, too, like \"Freddy vs. Jason.\"<br /><br />The Bad News: For fans of cheesy movies, this will be a great find. However, this film has a high cheese factor that may prevent the serious horror movie fan from having a good time enjoying this film. The film knows it is a cheesy movie and revels in it, making a serious fan turned off because of things like the one-liners. It isn\\'t all that bad of a movie, but it has to be watched in the mind frame that it is a cheesy movie, and that the cheesiness of certain scenes add to the movie, not to take it away. Remove yourself from that state of mind and you may find yourself enjoying this movie.<br /><br />The Final Verdict: Fans of cheesy movies and the other \"Child\\'s Play\" movies will find a lot to like about this movie. For serious horror fans, take a look at it, but keep in mind that it isn\\'t a serious movie and that the cheesiness is supposed to be there and you might find yourself liking it.<br /><br />Rated R: Graphic Violence, Graphic Language, Brief Nudity on a doll, a shadowy puppet sex scene, some drug use, and numerous drug references.', 'label': 1, 'input_ids': [101, 1000, 8959, 1997, 8057, 2100, 1000, 2003, 2028, 1997, 1996, 2488, 5469, 5691, 2000, 2272, 2041, 1999, 1996, 2627, 2702, 2086, 1998, 2071, 2022, 2028, 1997, 1996, 2190, 5469, 3152, 1997, 1996, 3938, 1005, 1055, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1008, 1008, 27594, 2545, 1008, 1008, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 8057, 2100, 1005, 1055, 6513, 1010, 14381, 1006, 7673, 6229, 2100, 1007, 9020, 2000, 2424, 2010, 17548, 3464, 2044, 2108, 8631, 2046, 1996, 5470, 2012, 1996, 2203, 1997, 2112, 1017, 1998, 7545, 2032, 2000, 2166, 1999, 2014, 9117, 2380, 1012, 2014, 11429, 1010, 10934, 1006, 4172, 17079, 9463, 1007, 1998, 2010, 6513, 12323, 1006, 9477, 2002, 8004, 2140, 1007, 2024, 2108, 29026, 2011, 2014, 4470, 1012, 1006, 2198, 23168, 1007, 14381, 6314, 2015, 8057, 2100, 2043, 2002, 10220, 2000, 5914, 2014, 1010, 2061, 2016, 23311, 1037, 10658, 2005, 2032, 2000, 2377, 2007, 1012, 8057, 2100, 8563, 14381, 1010, 1998, 2059, 15210, 2014, 3969, 2046, 1996, 10658, 2016, 2288, 2032, 1012, 1999, 2344, 2005, 2068, 2000, 2022, 2872, 2067, 2046, 2529, 4230, 1010, 2027, 2031, 2000, 3604, 2000, 2047, 3933, 2000, 12850, 2019, 25087, 2000, 2079, 2061, 1012, 10934, 5927, 2023, 2004, 2019, 4495, 2000, 4019, 2013, 23168, 1010, 1998, 2027, 2275, 2041, 2006, 1996, 4990, 1010, 2021, 2025, 2077, 23168, 2003, 2730, 2011, 8057, 2100, 1998, 14381, 1012, 2247, 1996, 2126, 1010, 2195, 13576, 10444, 2486, 2068, 2000, 2644, 2012, 1037, 2793, 1998, 6350, 1012, 2043, 2195, 2062, 2111, 2024, 2730, 1010, 2027, 2655, 2039, 2037, 2190, 2767, 1006, 5146, 12121, 19510, 2102, 1007, 2000, 28568, 2041, 1996, 3663, 1012, 2027, 8054, 2032, 4445, 2028, 1997, 2068, 2024, 1996, 15978, 1010, 2004, 1996, 2610, 2031, 2211, 2000, 9611, 1996, 6997, 1012, 2002, 4858, 23168, 1005, 1055, 2303, 1999, 1037, 8260, 1999, 1996, 2067, 1997, 1996, 3158, 1012, 3241, 2002, 2038, 2042, 2275, 2039, 1010, 2002, 17628, 2068, 2055, 2009, 1012, 8057, 2100, 1998, 14381, 2059, 2735, 2613, 2000, 6011, 2027, 2106, 2009, 1010, 2029, 4152, 12121, 19510, 2102, 2730, 1012, 1996, 2177, 15539, 1037, 5013, 2188, 1998, 8480, 2012, 1996, 4528, 1012, 10934, 1998, 12323, 2131, 8057, 2100, 1998, 14381, 2000, 2735, 2006, 2169, 2060, 1010, 3228, 2068, 2438, 2000, 4019, 1012, 8057, 2100, 27639, 2015, 12323, 1998, 2749, 2014, 2000, 2131, 2010, 25087, 1012, 8057, 2100, 1998, 14381, 23818, 2037, 13552, 1010, 2029, 3957, 10934, 1998, 12323, 2438, 2051, 2000, 3102, 1996, 2119, 1997, 2068, 2004, 1996, 2610, 7180, 1998, 28837, 2068, 1997, 1996, 6997, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2204, 2739, 1024, 1045, 2031, 2000, 2507, 1996, 2087, 3815, 1997, 24387, 2000, 1996, 23292, 2533, 1010, 2004, 8057, 2100, 1998, 14381, 2004, 14421, 2298, 3294, 13359, 1012, 1996, 5019, 2007, 2068, 2362, 2024, 1996, 5691, 2364, 11637, 1010, 2164, 1037, 26316, 4512, 2073, 14381, 25453, 8057, 2100, 2006, 2129, 7642, 15978, 1999, 1996, 3938, 1005, 1055, 2147, 1012, 2008, 2108, 2056, 1010, 1996, 3815, 1997, 2028, 1011, 11197, 2015, 1999, 2023, 3185, 2008, 2024, 2941, 6057, 2003, 9788, 1012, 8057, 2100, 4152, 1996, 2087, 1997, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_imdb['test'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18153b7b-7b1b-463c-bd7f-88d6e532a29a",
   "metadata": {},
   "source": [
    "### let's add padding to our input seq to make all i/p of equal length -> dynamic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bf28fdb-c1f8-48fe-a482-59cdf4e53548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_imdb['test'][-1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a47c9725-f8b5-4242-a4a7-d084851b4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24578d6d-1182-4d95-8f34-7a9ef47e0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938dcd5-393e-4bbc-a484-1371674cfd34",
   "metadata": {},
   "source": [
    "For training a model using trainer for which we need eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a2aed5b-64c7-4063-8a2c-01c385aaac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab8c413-6499-4a0e-9062-f78c1080f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e882a513-a34d-42e7-9165-f80ce769ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8710de1c-e31c-4d10-8554-fdd0961042fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31ee14e-71e3-4345-9ad3-995f8fbdea8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-uncased', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f369759-58a8-47be-94d2-21456e4062af",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='my_awesome_model',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3e1a71-3fe3-4f8a-9159-787d2464458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd3143b2-f77d-4832-b2ef-01ee74a111ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691493</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=0.6994994878768921, metrics={'train_runtime': 66.4071, 'train_samples_per_second': 0.151, 'train_steps_per_second': 0.015, 'total_flos': 1324673986560.0, 'train_loss': 0.6994994878768921, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d361431-9568-41a1-8de3-d7e7613c203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "267edb37-f058-4a88-9641-ed3ee7388ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.5024219155311584}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df23daf-0678-4e90-86c1-b2e0e37a811d",
   "metadata": {},
   "source": [
    "Since we barely trained our model, its score is always .50 for all text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ea64a-7bdf-4375-b004-8b24d0baeb31",
   "metadata": {},
   "source": [
    "## let's try to use already finetune distilbert from hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c959cc2b-077d-4057-97eb-e10b75eda3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128883c3f20242e5b439ce88eb2a1d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715f3a07f6fc46c39243ffe92400355b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33ccda2d304473799e3d03322878ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8a1fbd558a401f964aa8087880b071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3110461-14c4-448f-9c3a-2b2a8f37096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9994964599609375}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0263d20-d8e7-4e83-b1a3-50894901ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998799562454224}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ade9435-733e-4c85-92e1-d19de5c20baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996398687362671}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('I hate it')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
